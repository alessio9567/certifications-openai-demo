{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f6d39d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EMPLOYEE CODE', 'NAME', 'SURNAME', 'ORGANIZATIONAL UNIT',\n",
      "       'MANAGEMENT UNIT', 'CERTIFICATION', 'COMMENTS', 'CERTIFYING ENTITY',\n",
      "       'ISSUE DATE', 'VALIDITY DATE MODIFIED', 'NORMALIZED CERTIFICATION',\n",
      "       'EMAIL'],\n",
      "      dtype='object')\n",
      "Index(['Profess.', 'Name of the professional', 'Email', 'OU of the resource'], dtype='object')\n",
      "Index(['EMPLOYEE CODE', 'NAME', 'SURNAME', 'ORGANIZATIONAL UNIT',\n",
      "       'MANAGEMENT UNIT', 'CERTIFICATION', 'COMMENTS', 'CERTIFYING ENTITY',\n",
      "       'ISSUE DATE', 'VALIDITY DATE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Import inputs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path and sheet name\n",
    "file_path_1 = r'input\\certifications_additional_metadata_INPUT.xlsx'\n",
    "sheet_name_1 = 'Certificados'  # replace with the name of the sheet you want to read\n",
    "# Read the sheet into a DataFrame\n",
    "df_certif_adj = pd.read_excel(file_path_1, sheet_name=sheet_name_1, engine='openpyxl')\n",
    "# Display the first few rows of the DataFrame\n",
    "\n",
    "file_path_2 = r'input\\email.xlsx'\n",
    "sheet_name_2 = 'Plan de recursos'  # replace with the name of the sheet you want to read\n",
    "# Read the sheet into a DataFrame\n",
    "df_email = pd.read_excel(file_path_2, sheet_name=sheet_name_2, engine='openpyxl')\n",
    "\n",
    "file_path_3 = r'input\\export_certifications.xlsx'\n",
    "sheet_name_3 = 'Certificados'  # replace with the name of the sheet you want to read\n",
    "# Read the sheet into a DataFrame\n",
    "df_exp_cert = pd.read_excel(file_path_3, sheet_name=sheet_name_3, engine='openpyxl')\n",
    "\n",
    "print(df_certif_adj.columns)\n",
    "print(df_email.columns)\n",
    "\n",
    "print(df_exp_cert.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed4f3733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EMPLOYEE CODE      NAME     SURNAME         ORGANIZATIONAL UNIT  \\\n",
      "0            451927    ANDREA       CENSI     DBT I&D Data Management   \n",
      "1            451927    ANDREA       CENSI     DBT I&D Data Management   \n",
      "2            451927    ANDREA       CENSI     DBT I&D Data Management   \n",
      "3            451927    ANDREA       CENSI     DBT I&D Data Management   \n",
      "4            451927    ANDREA       CENSI     DBT I&D Data Management   \n",
      "...             ...       ...         ...                         ...   \n",
      "4468         470297   ALFREDO     SIRLETO  DBT I&D Advanced Analytics   \n",
      "4469         470297   ALFREDO     SIRLETO  DBT I&D Advanced Analytics   \n",
      "4470         470297   ALFREDO     SIRLETO  DBT I&D Advanced Analytics   \n",
      "4471         470297   ALFREDO     SIRLETO  DBT I&D Advanced Analytics   \n",
      "4472         576483  PATRIZIO  DI PASTENA  DBT I&D Advanced Analytics   \n",
      "\n",
      "                          MANAGEMENT UNIT  \\\n",
      "0     Digital Business Technologies (DBT)   \n",
      "1     Digital Business Technologies (DBT)   \n",
      "2     Digital Business Technologies (DBT)   \n",
      "3     Digital Business Technologies (DBT)   \n",
      "4     Digital Business Technologies (DBT)   \n",
      "...                                   ...   \n",
      "4468  Digital Business Technologies (DBT)   \n",
      "4469  Digital Business Technologies (DBT)   \n",
      "4470  Digital Business Technologies (DBT)   \n",
      "4471  Digital Business Technologies (DBT)   \n",
      "4472  Digital Business Technologies (DBT)   \n",
      "\n",
      "                                          CERTIFICATION  \\\n",
      "0     CLOUD INTEGRATION FOR APPLICATION MODERNIZATIO...   \n",
      "1     CLOUD INTEGRATION FOR APPLICATION MODERNIZATIO...   \n",
      "2     CLOUD INTEGRATION FOR APPLICATION MODERNIZATIO...   \n",
      "3     CLOUD INTEGRATION FOR APPLICATION MODERNIZATIO...   \n",
      "4     CLOUD INTEGRATION FOR APPLICATION MODERNIZATIO...   \n",
      "...                                                 ...   \n",
      "4468                       (SMC) SCRUM MASTER CERTIFIED   \n",
      "4469                       (SMC) SCRUM MASTER CERTIFIED   \n",
      "4470                       (SMC) SCRUM MASTER CERTIFIED   \n",
      "4471                       (SMC) SCRUM MASTER CERTIFIED   \n",
      "4472                           CDP CERTIFIED GENERALIST   \n",
      "\n",
      "                                               COMMENTS  \\\n",
      "0     APPLICATION MODERNIZATION : MARKET TRENDS, ARC...   \n",
      "1     APPLICATION MODERNIZATION : MARKET TRENDS, ARC...   \n",
      "2     APPLICATION MODERNIZATION : MARKET TRENDS, ARC...   \n",
      "3     APPLICATION MODERNIZATION : MARKET TRENDS, ARC...   \n",
      "4     APPLICATION MODERNIZATION : MARKET TRENDS, ARC...   \n",
      "...                                                 ...   \n",
      "4468                                                NaN   \n",
      "4469                                                NaN   \n",
      "4470                                                NaN   \n",
      "4471                                                NaN   \n",
      "4472                                                NaN   \n",
      "\n",
      "           CERTIFYING ENTITY  ISSUE DATE  VALIDITY DATE MODIFIED  \n",
      "0     Informatica University  07/04/2022                     NaN  \n",
      "1     Informatica University  07/04/2022                     NaN  \n",
      "2     Informatica University  07/04/2022                     NaN  \n",
      "3     Informatica University  07/04/2022                     NaN  \n",
      "4     Informatica University  07/04/2022                     NaN  \n",
      "...                      ...         ...                     ...  \n",
      "4468              SCRUMstudy  16/11/2018                     NaN  \n",
      "4469              SCRUMstudy  16/11/2018                     NaN  \n",
      "4470              SCRUMstudy  16/11/2018                     NaN  \n",
      "4471              SCRUMstudy  16/11/2018                     NaN  \n",
      "4472          Cloudera, Inc.  15/06/2023                     NaN  \n",
      "\n",
      "[4473 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Join all inputs\n",
    "\n",
    "df_certif_adj = df_certif_adj[['EMPLOYEE CODE','VALIDITY DATE MODIFIED']]\n",
    "merged_df_valid = pd.merge(df_exp_cert, df_certif_adj, on='EMPLOYEE CODE', how='left')  \n",
    "merged_df_valid.drop(['VALIDITY DATE'], axis=1, inplace=True)\n",
    "print(merged_df_valid)\n",
    "\n",
    "df_email = df_email[['Profess.','Email']]\n",
    "df_email.rename(columns={'Profess.': 'EMPLOYEE CODE'}, inplace=True)\n",
    "merged_df_valid_email = pd.merge(merged_df_valid, df_email, on='EMPLOYEE CODE', how='left')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bf99ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiannini\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\aiannini\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain\\llms\\openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Normalize certifications\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    " \n",
    "# Initialize envirnonment variable OPENAI_API_KEY with your API key \n",
    "with open('api_key.txt', 'r') as file:\n",
    "    # Read the first line\n",
    "    os.environ['OPENAI_API_KEY'] = file.readline().strip()  \n",
    "\n",
    "# Template for the prompt\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template,input_variables=['question'])\n",
    "\n",
    "\n",
    "# OpenAI model\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo-16k\",temperature=0)\n",
    "\n",
    "\n",
    "# LLMChain\n",
    "llm_chain = LLMChain(\n",
    "prompt=prompt,\n",
    "llm=model\n",
    ")\n",
    "\n",
    "distinct_values_certifications = merged_df_valid_email['CERTIFICATION'].unique()\n",
    "\n",
    "cert_list_str=''\n",
    "for elem in distinct_values_certifications:\n",
    "    cert_list_str=cert_list_str + str(elem) + '\\n'\n",
    "\n",
    "question=\"\"\" \n",
    "\n",
    "Under the '***' marker, you'll find a collection of technical certifications.\n",
    "\n",
    "Some of these certifications have different text representations, but they essentially represent the same qualifications.\n",
    "\n",
    "First, identify certifications with multiple names.\n",
    "\n",
    "Next, standardize the names by assigning a unique one to each.\n",
    "\n",
    "Record the results in a CSV file using a semicolon as the delimiter, including two fields:\n",
    "\n",
    "The original certification name\n",
    "The standardized certification name\n",
    "\n",
    "***\n",
    "\"\"\"+cert_list_str\n",
    "#print(question)\n",
    "\n",
    "\n",
    "# Run the model\n",
    "answer = llm_chain.run(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e1cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "# Split the input string into lines\n",
    "lines = answer.strip().split('\\n')\n",
    "\n",
    "# Specify the output file path (e.g., 'output.csv')\n",
    "output_file_path = 'certifications_normalized.csv'\n",
    "\n",
    "# Write the content to a CSV file with a semicolon delimiter\n",
    "with open(output_file_path, 'w', newline='') as outfile:\n",
    "    csv_writer = csv.writer(outfile, delimiter=';')  # Specify the delimiter\n",
    "    for line in lines:\n",
    "        row = line.split(';')\n",
    "        csv_writer.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a9e7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    " \n",
    "# Create a DataFrame from the openai answer\n",
    "df_normalized_certifications = pd.read_csv(StringIO(answer), sep=';') \n",
    "\n",
    "df_output = pd.merge(merged_df_valid_email, df_normalized_certifications, left_on='CERTIFICATION', right_on='Original Certification Name', how='inner')\n",
    "\n",
    "df_output = df_output.rename(columns={' Standardized Certification Name': 'NORMALIZED CERTIFICATION'})\n",
    "\n",
    "df_output.loc[df_output['CERTIFYING ENTITY'] == 'Tibco Software', 'NORMALIZED CERTIFICATION'] = df_output['CERTIFICATION']\n",
    "\n",
    "df_output = df_output[['EMPLOYEE CODE','NAME','SURNAME','ORGANIZATIONAL UNIT','MANAGEMENT UNIT','CERTIFICATION',\n",
    "                       'COMMENTS','CERTIFYING ENTITY','ISSUE DATE','VALIDITY DATE MODIFIED','NORMALIZED CERTIFICATION']]\n",
    "\n",
    "df_output['NORMALIZED CERTIFICATION'] = df_output['NORMALIZED CERTIFICATION'].str.lstrip()\n",
    "\n",
    "df_output = df_output.drop_duplicates(subset=['EMPLOYEE CODE', 'NORMALIZED CERTIFICATION'])\n",
    "\n",
    "df_output.to_excel('output/certifications_additional_metadata_OUTPUT_IANNINI.xlsx',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
